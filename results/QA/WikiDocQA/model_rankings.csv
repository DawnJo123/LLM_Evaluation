Model,Average Rank,rouge1_score,rouge1_rank,rouge2_score,rouge2_rank,rougeL_score,rougeL_rank,bleu_score,bleu_rank,meteor_score,meteor_rank,semantic_similarity_score,semantic_similarity_rank
groq_gemma2-9b-it,1.5,0.24034202014992048,1,0.05713763812867792,1,0.13906919148194732,1,0.016429438242153146,1,0.22361625021216588,2,0.9195156174898148,3
azure_gpt-4o-mini,1.6666666666666667,0.2332273597374184,2,0.05285991645089021,2,0.1287325031554478,2,0.01579616114990089,2,0.23269084821333286,1,0.9257673490047454,1
groq_mistral-saba-24b,3.5,0.2054153937595675,3,0.05179993886150873,3,0.11154481430365093,5,0.014207619968796319,5,0.21872277296009027,3,0.920383186340332,2
groq_llama-3.3-70b-versatile,3.6666666666666665,0.2019593446944955,4,0.04920124894240004,4,0.11379193946585194,3,0.015128000205233895,3,0.21662786025748,4,0.9186751997470856,4
groq_llama-3.1-8b-instant,4.666666666666667,0.19562229104955212,5,0.04729079985929646,5,0.11168946656578305,4,0.014798244962809902,4,0.21487758657414802,5,0.9171198838949204,5
