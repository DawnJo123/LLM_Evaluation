{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf0f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dec5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a04d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCQ\n",
    "mmlu_pro_medicine = load_dataset(\"openlifescienceai/mmlu_professional_medicine\")\n",
    "mmlu_anatomy = load_dataset(\"openlifescienceai/mmlu_anatomy\")\n",
    "mmlu_clinical_knowledge = load_dataset(\"openlifescienceai/mmlu_clinical_knowledge\")\n",
    "pubmedqa = load_dataset(\"openlifescienceai/pubmedqa\")\n",
    "\n",
    "#Text Summarization\n",
    "cord19_summarization = load_dataset(\"medalpaca/medical_meadow_cord19\")\n",
    "\n",
    "#QA\n",
    "wikidoc_qa = load_dataset(\"medalpaca/medical_meadow_wikidoc_patient_information\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3a026",
   "metadata": {},
   "source": [
    "# Dataset Inspection\n",
    "\n",
    "Let's take a look at the structure of one of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b723ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['subject_name', 'data', 'id'],\n",
      "        num_rows: 272\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['subject_name', 'data', 'id'],\n",
      "        num_rows: 31\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['subject_name', 'data', 'id'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample from 'dev' split:\n",
      "{'subject_name': 'professional_medicine', 'data': {'Correct Answer': 'Phenoxybenzamine', 'Correct Option': 'D', 'Options': {'A': 'Labetalol', 'B': 'A loading dose of potassium chloride', 'C': 'Nifedipine', 'D': 'Phenoxybenzamine'}, 'Question': 'A 42-year-old man comes to the office for preoperative evaluation prior to undergoing adrenalectomy scheduled in 2 weeks. One month ago, he received care in the emergency department for pain over his right flank following a motor vehicle collision. At that time, blood pressure was 160/100 mm Hg and CT scan of the abdomen showed an incidental 10-cm left adrenal mass. Results of laboratory studies, including complete blood count, serum electrolyte concentrations, and liver function tests, were within the reference ranges. The patient otherwise had been healthy and had never been told that he had elevated blood pressure. He takes no medications. A follow-up visit in the office 2 weeks ago disclosed elevated urinary normetanephrine and metanephrine and plasma aldosterone concentrations. The patient was referred to a surgeon, who recommended the adrenalectomy. Today, vital signs are temperature 36.6°C (97.9°F), pulse 100/min, respirations 14/min, and blood pressure 170/95 mm Hg. Physical examination discloses no significant findings. Initial preoperative preparation should include treatment with which of the following?'}, 'id': '693c45e8-7cda-46ef-8bcb-4a311471621e'}\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about mmlu_pro_medicine dataset\n",
    "print(\"Dataset structure:\")\n",
    "print(mmlu_pro_medicine)\n",
    "\n",
    "# View a sample from the dataset\n",
    "print(\"\\nSample from 'dev' split:\")\n",
    "sample = mmlu_pro_medicine['dev'][0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc463f74",
   "metadata": {},
   "source": [
    "# Save Datasets to CSV (Limited to 500 samples)\n",
    "\n",
    "We'll convert each dataset to CSV format and save a maximum of 500 samples to the raw data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0fa8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "def save_limited_dataset_to_csv(dataset, dataset_name, max_samples=500):\n",
    "    # Collect all samples from the dataset across splits\n",
    "    all_samples = []\n",
    "    for split_name, split_data in dataset.items():\n",
    "        df = split_data.to_pandas()\n",
    "        all_samples.append(df)\n",
    "    \n",
    "    # Combine all splits\n",
    "    combined_df = pd.concat(all_samples, ignore_index=True)\n",
    "    print(f\"Total samples in {dataset_name}: {len(combined_df)}\")\n",
    "    \n",
    "    # Randomly select max_samples or all if fewer\n",
    "    if len(combined_df) > max_samples:\n",
    "        sampled_df = combined_df.sample(max_samples, random_state=42)\n",
    "    else:\n",
    "        sampled_df = combined_df\n",
    "    \n",
    "    # Save to CSV in raw data folder\n",
    "    output_path = f\"data/raw/{dataset_name}.csv\"\n",
    "    sampled_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(sampled_df)} samples from {dataset_name} to {output_path}\")\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172066a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in mmlu_prof_med: 308\n",
      "Saved 308 samples from mmlu_prof_med to data/raw/mmlu_prof_med.csv\n",
      "Total samples in mmlu_anatomy: 154\n",
      "Saved 154 samples from mmlu_anatomy to data/raw/mmlu_anatomy.csv\n",
      "Total samples in mmlu_clinical_knowledge: 299\n",
      "Saved 299 samples from mmlu_clinical_knowledge to data/raw/mmlu_clinical_knowledge.csv\n",
      "Total samples in pubmedqa: 1000\n",
      "Saved 500 samples from pubmedqa to data/raw/pubmedqa.csv\n"
     ]
    }
   ],
   "source": [
    "# Save medical datasets (limited to 500 samples each)\n",
    "mmlu_med_samples = save_limited_dataset_to_csv(mmlu_pro_medicine, \"mmlu_prof_med\")\n",
    "mmlu_anat_samples = save_limited_dataset_to_csv(mmlu_anatomy, \"mmlu_anatomy\")\n",
    "mmlu_clin_samples = save_limited_dataset_to_csv(mmlu_clinical_knowledge, \"mmlu_clinical_knowledge\")\n",
    "pubmedqa_samples = save_limited_dataset_to_csv(pubmedqa, \"pubmedqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f261abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in cord19_summarization: 821007\n",
      "Saved 500 samples from cord19_summarization to data/raw/cord19_summarization.csv\n",
      "Total samples in wikidoc_qa: 5942\n",
      "Saved 500 samples from wikidoc_qa to data/raw/wikidoc_qa.csv\n",
      "Total samples in wikidoc_qa: 5942\n",
      "Saved 500 samples from wikidoc_qa to data/raw/wikidoc_qa.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the summarization and QA datasets (limited to 500 samples each)\n",
    "cord19_samples = save_limited_dataset_to_csv(cord19_summarization, \"cord19_summarization\")\n",
    "wikidoc_samples = save_limited_dataset_to_csv(wikidoc_qa, \"wikidoc_qa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2020e3",
   "metadata": {},
   "source": [
    "# Combine 600 Random Samples from Medical MCQ Datasets\n",
    "\n",
    "Let's create a combined dataset with 600 randomly selected samples from the three medical MCQ datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfb4233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional Medicine dataset: 308 samples\n",
      "Anatomy dataset: 154 samples\n",
      "Clinical Knowledge dataset: 299 samples\n",
      "\n",
      "Sampling: 200 from Medicine, 154 from Anatomy, 246 from Clinical Knowledge\n"
     ]
    }
   ],
   "source": [
    "# Load the saved CSV files\n",
    "med_df = pd.read_csv('data/raw/mmlu_prof_med.csv')\n",
    "anat_df = pd.read_csv('data/raw/mmlu_anatomy.csv')\n",
    "clin_df = pd.read_csv('data/raw/mmlu_clinical_knowledge.csv')\n",
    "\n",
    "# Check the number of samples in each dataset\n",
    "print(f\"Professional Medicine dataset: {len(med_df)} samples\")\n",
    "print(f\"Anatomy dataset: {len(anat_df)} samples\")\n",
    "print(f\"Clinical Knowledge dataset: {len(clin_df)} samples\")\n",
    "\n",
    "# Calculate how many samples to take from each dataset\n",
    "# We'll aim for an approximately equal distribution\n",
    "samples_per_dataset = 600 // 3\n",
    "\n",
    "# If there are fewer samples in any dataset, adjust accordingly\n",
    "med_samples = min(samples_per_dataset, len(med_df))\n",
    "anat_samples = min(samples_per_dataset, len(anat_df))\n",
    "clin_samples = 600 - med_samples - anat_samples  # Make sure we get exactly 600 total\n",
    "\n",
    "print(f\"\\nSampling: {med_samples} from Medicine, {anat_samples} from Anatomy, {clin_samples} from Clinical Knowledge\")\n",
    "\n",
    "# Randomly sample from each dataset\n",
    "med_subset = med_df.sample(med_samples, random_state=42)\n",
    "anat_subset = anat_df.sample(anat_samples, random_state=42)\n",
    "clin_subset = clin_df.sample(clin_samples, random_state=42)\n",
    "\n",
    "# Add a source column to track where each question came from\n",
    "med_subset['source'] = 'Professional Medicine'\n",
    "anat_subset['source'] = 'Anatomy'\n",
    "clin_subset['source'] = 'Clinical Knowledge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e51c3",
   "metadata": {},
   "source": [
    "# Format data and extract required columns\n",
    "\n",
    "Now we'll transform the dataset by:\n",
    "1. Removing the subject_name column\n",
    "2. Creating input column (combining Question and Options)\n",
    "3. Extracting the original 'Correct Answer' and 'Correct Option' fields\n",
    "4. Keeping source column for reference but dropping id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d459f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset with 600 samples saved to data/processed/combined_medical_mcq_600.csv\n",
      "Dataset distribution:\n",
      "source\n",
      "Clinical Knowledge       246\n",
      "Professional Medicine    200\n",
      "Anatomy                  154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def format_mcq_data(df):\n",
    "    formatted_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        data_dict = eval(row['data']) if isinstance(row['data'], str) else row['data']\n",
    "        \n",
    "        # Extract question and options\n",
    "        question = data_dict.get('Question', '')\n",
    "        options = data_dict.get('Options', {})\n",
    "        \n",
    "        # Format options as A. option, B. option, etc.\n",
    "        formatted_options = '\\n'.join([f\"{k}. {v}\" for k, v in options.items()])\n",
    "        \n",
    "        # Create input by combining question and options\n",
    "        input_text = f\"{question}\\n\\n{formatted_options}\"\n",
    "        \n",
    "        # Get the correct answer and option\n",
    "        correct_answer = data_dict.get('Correct Answer', '')\n",
    "        correct_option = data_dict.get('Correct Option', '')\n",
    "        \n",
    "        formatted_rows.append({\n",
    "            'input': input_text,\n",
    "            'Correct Answer': correct_answer,\n",
    "            'Correct Option': correct_option,\n",
    "            'source': row['source']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(formatted_rows)\n",
    "\n",
    "# Format each subset\n",
    "med_formatted = format_mcq_data(med_subset)\n",
    "anat_formatted = format_mcq_data(anat_subset)\n",
    "clin_formatted = format_mcq_data(clin_subset)\n",
    "\n",
    "# Combine the formatted datasets\n",
    "combined_df = pd.concat([med_formatted, anat_formatted, clin_formatted], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "output_path = \"data/processed/combined_medical_mcq_600.csv\"\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nCombined dataset with {len(combined_df)} samples saved to {output_path}\")\n",
    "print(f\"Dataset distribution:\")\n",
    "print(combined_df['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ec175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset columns:\n",
      "['input', 'Correct Answer', 'Correct Option', 'source']\n",
      "\n",
      "Sample from combined dataset:\n",
      "input             A 50-year-old female presents to the office wi...\n",
      "Correct Answer                                         fibromyalgia\n",
      "Correct Option                                                    B\n",
      "source                                        Professional Medicine\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the combined dataset\n",
    "print(\"Combined dataset columns:\")\n",
    "print(combined_df.columns.tolist())\n",
    "print(\"\\nSample from combined dataset:\")\n",
    "print(combined_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07cb187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in wikidoc_qa dataset: 500\n",
      "Warning: Only 500 records available in dataset, using all records.\n",
      "Number of samples with both input and output: 500\n",
      "Complete records after dropping rows with missing values: 500\n",
      "Saved 500 input-output pairs to data/processed/wikidoc_qa_600.csv\n",
      "Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where to find Medical Care for Gonadoblastoma?</td>\n",
       "      <td>Medical care for gonadoblastoma can be found h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What to expect if I have Craniosynostosis  (Ou...</td>\n",
       "      <td>How well a person does depends on how many sut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When to seek urgent medical care when I have S...</td>\n",
       "      <td>Call for an appointment with your health care ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0     Where to find Medical Care for Gonadoblastoma?   \n",
       "1  What to expect if I have Craniosynostosis  (Ou...   \n",
       "2  When to seek urgent medical care when I have S...   \n",
       "\n",
       "                                              output  \n",
       "0  Medical care for gonadoblastoma can be found h...  \n",
       "1  How well a person does depends on how many sut...  \n",
       "2  Call for an appointment with your health care ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 600 records from wikidoc_qa dataset and save to processed folder\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if we already have the wikidoc_samples dataframe in memory\n",
    "if 'wikidoc_samples' not in globals() or len(wikidoc_samples) < 600:\n",
    "    # Load the CSV file if we need to\n",
    "    wikidoc_df = pd.read_csv('data/raw/wikidoc_qa.csv')\n",
    "    print(f\"Total records in wikidoc_qa dataset: {len(wikidoc_df)}\")\n",
    "    \n",
    "    # Sample 600 records randomly if the dataset is large enough\n",
    "    if len(wikidoc_df) >= 600:\n",
    "        wikidoc_samples = wikidoc_df.sample(n=600, random_state=42)\n",
    "    else:\n",
    "        # If dataset is smaller than 600, use all available records\n",
    "        wikidoc_samples = wikidoc_df\n",
    "        print(f\"Warning: Only {len(wikidoc_df)} records available in dataset, using all records.\")\n",
    "\n",
    "# Ensure we have complete input-output pairs\n",
    "print(f\"Number of samples with both input and output: {wikidoc_samples[['input', 'output']].notna().all(axis=1).sum()}\")\n",
    "    \n",
    "# Remove any rows with missing input or output (if any)\n",
    "wikidoc_complete = wikidoc_samples.dropna(subset=['input', 'output'])\n",
    "print(f\"Complete records after dropping rows with missing values: {len(wikidoc_complete)}\")\n",
    "\n",
    "# If we have more than 600 complete records, sample exactly 600\n",
    "if len(wikidoc_complete) > 600:\n",
    "    wikidoc_complete = wikidoc_complete.sample(n=600, random_state=42)\n",
    "    \n",
    "# Save the sampled data to the processed folder\n",
    "processed_path = \"data/processed/wikidoc_qa_600.csv\"\n",
    "wikidoc_complete.to_csv(processed_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(wikidoc_complete)} input-output pairs to {processed_path}\")\n",
    "print(f\"Sample of the data:\")\n",
    "wikidoc_complete[['input', 'output']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf4c4344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (500, 3)\n",
      "\n",
      "Column names:\n",
      "- input\n",
      "- output\n",
      "- instruction\n",
      "\n",
      "Number of unique input questions: 499\n",
      "Number of unique output answers: 499\n",
      "\n",
      "Sample input question:\n",
      "Where to find Medical Care for Gonadoblastoma?\n",
      "\n",
      "Sample output answer:\n",
      "Medical care for gonadoblastoma can be found here.\n"
     ]
    }
   ],
   "source": [
    "# Verify the wikidoc dataset structure and contents\n",
    "print(f\"Dataset shape: {wikidoc_complete.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for col in wikidoc_complete.columns:\n",
    "    print(f\"- {col}\")\n",
    "    \n",
    "# Count unique questions and answers\n",
    "print(f\"\\nNumber of unique input questions: {wikidoc_complete['input'].nunique()}\")\n",
    "print(f\"Number of unique output answers: {wikidoc_complete['output'].nunique()}\")\n",
    "\n",
    "# Display example input and output\n",
    "print(\"\\nSample input question:\")\n",
    "print(wikidoc_complete['input'].iloc[0])\n",
    "\n",
    "print(\"\\nSample output answer:\")\n",
    "print(wikidoc_complete['output'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e5356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 500 records available in dataset, using all records.\n",
      "Saved 500 records to data/processed/cord19_summarization_600.csv\n",
      "Sample of the data:\n",
      "\n",
      "Saved 500 records to data/processed/cord19_summarization_600.csv\n",
      "Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183. Decrease in Invasive Pneumococcal Disease...</td>\n",
       "      <td>BACKGROUND: During the 2020 SARS-CoV-2 pandemi...</td>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD10 in the developing human kidney: immunorea...</td>\n",
       "      <td>CD10 was first identified in tumor cells of ac...</td>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long-term bone and lung consequences associate...</td>\n",
       "      <td>The most severe sequelae after rehabilitation ...</td>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNA structure interactions and ribonucleoprote...</td>\n",
       "      <td>In one more years, we will ‘celebrate’ an exac...</td>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organization of remote rehabilitation of mosco...</td>\n",
       "      <td>The tense epidemic situation in the Russian Fe...</td>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              output  \\\n",
       "0  183. Decrease in Invasive Pneumococcal Disease...   \n",
       "1  CD10 in the developing human kidney: immunorea...   \n",
       "2  Long-term bone and lung consequences associate...   \n",
       "3  RNA structure interactions and ribonucleoprote...   \n",
       "4  Organization of remote rehabilitation of mosco...   \n",
       "\n",
       "                                               input  \\\n",
       "0  BACKGROUND: During the 2020 SARS-CoV-2 pandemi...   \n",
       "1  CD10 was first identified in tumor cells of ac...   \n",
       "2  The most severe sequelae after rehabilitation ...   \n",
       "3  In one more years, we will ‘celebrate’ an exac...   \n",
       "4  The tense epidemic situation in the Russian Fe...   \n",
       "\n",
       "                                      instruction  \n",
       "0  Please summerize the given abstract to a title  \n",
       "1  Please summerize the given abstract to a title  \n",
       "2  Please summerize the given abstract to a title  \n",
       "3  Please summerize the given abstract to a title  \n",
       "4  Please summerize the given abstract to a title  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 600 records from cord19_summarization dataset and save to processed folder\\n\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Check if we already have the cord19_samples dataframe in memory\\n\n",
    "if 'cord19_samples' not in globals() or len(cord19_samples) < 600:\n",
    "    # Load the CSV file if we need to\\n\n",
    "    cord19_df = pd.read_csv('data/raw/cord19_summarization.csv')\n",
    "    # Sample 600 records randomly if the dataset is large enough\\n\n",
    "    if len(cord19_df) >= 600:\n",
    "        cord19_samples = cord19_df.sample(n=600, random_state=42)\n",
    "    else:\n",
    "        # If dataset is smaller than 600, use all available records\\n\n",
    "        cord19_samples = cord19_df\n",
    "        print(f\"Warning: Only {len(cord19_df)} records available in dataset, using all records.\")\n",
    "\n",
    "# Save the sampled data to the processed folder\\n\n",
    "processed_path = \"data/processed/cord19_summarization_600.csv\"\n",
    "cord19_samples.to_csv(processed_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(cord19_samples)} records to {processed_path}\")\n",
    "print(f\"Sample of the data:\")\n",
    "cord19_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22f62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dbb0b5a",
   "metadata": {},
   "source": [
    "# Process PubMedQA Dataset\n",
    "\n",
    "Extract information from the PubMedQA dataset, restructure it, and save to processed folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35803ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed PubMedQA dataset:\n",
      "Shape: (500, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>correct_option</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>long_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Mossy fibers are the sole excitatory project...</td>\n",
       "      <td>Do mossy fibers release GABA?</td>\n",
       "      <td>{'A': 'yes', 'B': 'no', 'C': 'maybe'}</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>We have thus provided compelling evidence that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Research on stroke survivors' driving safety...</td>\n",
       "      <td>Department of Transportation vs self-reported ...</td>\n",
       "      <td>{'A': 'yes', 'B': 'no', 'C': 'maybe'}</td>\n",
       "      <td>B</td>\n",
       "      <td>no</td>\n",
       "      <td>In our population of stroke survivors, self-re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  ['Mossy fibers are the sole excitatory project...   \n",
       "1  [\"Research on stroke survivors' driving safety...   \n",
       "\n",
       "                                            question  \\\n",
       "0                      Do mossy fibers release GABA?   \n",
       "1  Department of Transportation vs self-reported ...   \n",
       "\n",
       "                                 options correct_option correct_answer  \\\n",
       "0  {'A': 'yes', 'B': 'no', 'C': 'maybe'}              A            yes   \n",
       "1  {'A': 'yes', 'B': 'no', 'C': 'maybe'}              B             no   \n",
       "\n",
       "                                         long_answer  \n",
       "0  We have thus provided compelling evidence that...  \n",
       "1  In our population of stroke survivors, self-re...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process PubMedQA dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Load the PubMedQA dataset from raw data if not already in memory\n",
    "if 'pubmedqa_samples' not in globals():\n",
    "    pubmed_df = pd.read_csv('data/raw/pubmedqa.csv')\n",
    "else:\n",
    "    pubmed_df = pd.DataFrame(pubmedqa_samples)\n",
    "\n",
    "# Function to extract data from the 'data' column\n",
    "def extract_pubmedqa_data(data_str):\n",
    "    try:\n",
    "        # Convert string to dictionary if it's a string\n",
    "        if isinstance(data_str, str):\n",
    "            data_dict = ast.literal_eval(data_str)\n",
    "        else:\n",
    "            data_dict = data_str\n",
    "            \n",
    "        # Extract the fields\n",
    "        context = ' '.join(data_dict.get('Context', [])) if isinstance(data_dict.get('Context'), list) else str(data_dict.get('Context', ''))\n",
    "        question = data_dict.get('Question', '')\n",
    "        options = data_dict.get('Options', {})\n",
    "        correct_option = data_dict.get('Correct Option', '')\n",
    "        correct_answer = data_dict.get('Correct Answer', '')\n",
    "        long_answer = data_dict.get('Long Answer', '')\n",
    "        \n",
    "        return context, question, options, correct_option, correct_answer, long_answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return '', '', {}, '', '', ''\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "results = pubmed_df['data'].apply(extract_pubmedqa_data)\n",
    "\n",
    "# Create a new DataFrame with the extracted data\n",
    "processed_df = pd.DataFrame({\n",
    "    'context': [r[0] for r in results],\n",
    "    'question': [r[1] for r in results],\n",
    "    'options': [r[2] for r in results],\n",
    "    'correct_option': [r[3] for r in results],\n",
    "    'correct_answer': [r[4] for r in results],\n",
    "    'long_answer': [r[5] for r in results]\n",
    "})\n",
    "\n",
    "# Display the first few rows to verify the extraction\n",
    "print(\"Processed PubMedQA dataset:\")\n",
    "print(f\"Shape: {processed_df.shape}\")\n",
    "processed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee790441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed PubMedQA dataset saved to data/processed/pubmedqa_processed.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataset to the processed folder\n",
    "processed_path = \"data/processed/pubmedqa_processed.csv\"\n",
    "processed_df.to_csv(processed_path, index=False)\n",
    "print(f\"Processed PubMedQA dataset saved to {processed_path}\")\n",
    "\n",
    "# Sample 600 records for consistency with other datasets (if needed)\n",
    "if len(processed_df) > 600:\n",
    "    sample_df = processed_df.sample(n=600, random_state=42)\n",
    "    sample_path = \"data/processed/pubmedqa_600.csv\"\n",
    "    sample_df.to_csv(sample_path, index=False)\n",
    "    print(f\"Random sample of 600 records saved to {sample_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89030543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (500, 3)\n",
      "\n",
      "Column names:\n",
      "- output\n",
      "- input\n",
      "- instruction\n",
      "\n",
      "Sample output title:\n",
      "183. Decrease in Invasive Pneumococcal Disease in 7 United States Children’s Hospitals during the COVID-19 Pandemic\n"
     ]
    }
   ],
   "source": [
    "# Verify the dataset structure and contents\\n\n",
    "print(f\"Dataset shape: {cord19_samples.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for col in cord19_samples.columns:\n",
    "    print(f\"- {col}\")\n",
    "print(\"\\nSample output title:\")\n",
    "print(cord19_samples['output'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78d140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
